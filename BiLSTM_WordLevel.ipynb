{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/notmanan/Depression-Detection-Through-Multi-Modal-Data/blob/master/BiLSTM_WordLevel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","metadata":{"id":"tasUx7g7tj6-","outputId":"55d48e7c-dbbf-47ce-8389-3b7d0cef21d5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681397972120,"user_tz":-330,"elapsed":51749,"user":{"displayName":"Deepression SLP","userId":"18338550655322334499"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"xEsJLX-D75EI"},"source":["MAKE DATASET"]},{"cell_type":"code","metadata":{"id":"noxzoJZvuPDR","outputId":"2b6b2d63-7d5f-4e68-ed51-cc4f37a756ed","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681398319741,"user_tz":-330,"elapsed":283268,"user":{"displayName":"Deepression SLP","userId":"18338550655322334499"}}},"source":["import nltk\n","nltk.download('stopwords')\n","import numpy as np\n","import pandas as pd\n","from gensim.models.keyedvectors import KeyedVectors\n","import gc\n","import math\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Flatten\n","from keras.layers import Dense\n","from smart_open import open\n","from nltk.corpus import stopwords\n","from sklearn.metrics import classification_report\n","from keras.layers import Dropout\n","from matplotlib import pyplot as plt\n","\n","dev_location = \"302_P\"\n","test_location = \"300_P\"\n","train_location = \"303_P\"\n","\n","devData = np.array(pd.read_csv('/content/drive/My Drive/MCA Dataset/devdata.csv',delimiter=',',encoding='utf-8'))[:, 0:4]\n","testData = np.array(pd.read_csv('/content/drive/My Drive/MCA Dataset/testdata.csv',delimiter=',',encoding='utf-8'))[:, 0:4]\n","trainData = np.array(pd.read_csv('/content/drive/My Drive/MCA Dataset/traindata.csv',delimiter=',',encoding='utf-8'))[:, 0:4]\n","\n","dataset = np.concatenate((devData, np.concatenate((testData, trainData))))\n","\n","\n","# print(dataset)\n","gc.collect()      \n","max_num_words = 17\n","model = KeyedVectors.load_word2vec_format('/content/drive/My Drive/MCA Dataset/GoogleNews-vectors-negative300.bin', binary=True)\n","stop_words = set(stopwords.words('english'))\n","\n","def checkDataPointExistence(patientID, split):\n","  for i in split:\n","    if(patientID == i[0]):\n","      return True\n","  return False\n","\n","def getData(patientID, location):\n","  # print(\"PatientID: \" + str(int(patientID)))\n","  retData = [int(patientID)]\n","  textD = getTextData(patientID, location)\n","  textD = np.array(textD)\n","  audioD = getAudioData(patientID, location, textD)\n","  return textD,audioD\n","\n","def getTextData(patientID, location):\n","  fileName = \"/content/drive/My Drive/MCA Dataset/\"+ location + \"/\" + str(int(patientID)) + \"_TRANSCRIPT.csv\"\n","  file = np.array(pd.read_csv(fileName,delimiter='\\t',encoding='utf-8', engine='python'))\n","  outputList = []\n","\n","  for i in range(len(file)):\n","    sentence = file[i][3]\n","    words = str(sentence).split(\" \")\n","    totalWordLength = 0\n","    for word in words: \n","      totalWordLength += len(word)\n","\n","    sentenceStart = file[i][0] \n","    sentenceEnd = file[i][1]\n","    speaker = file[i][2]\n","    if speaker == 'Ellie':\n","      continue\n","    else:\n","      speaker = 1\n","\n","    totalTime = sentenceEnd - sentenceStart\n","    timePerChar = totalTime/totalWordLength\n","\n","    wordStart = sentenceStart\n","    for word in words:\n","      wordEnd = wordStart + (timePerChar * len(word))\n","      appender = [wordStart, wordEnd, speaker]\n","      vector = list(returnWordToVec(word))\n","      for v in vector:\n","        appender.append(v)\n","      # print(appender)\n","      # print(len(appender))\n","      outputList.append(appender)\n","      wordStart = wordEnd\n","\n","  return outputList\n","\n","\n","def remove_StopWords(sentence):\n","    filtered_sentence = [] \n","    for w in sentence: \n","        if w not in stop_words: \n","            filtered_sentence.append(w)\n","    return filtered_sentence\n","\n","\n","def returnWordToVec(word):\n","  word = str(word)\n","  try:\n","    if word[0] == '<':\n","        word = word[1:]\n","    if word[-1] == '>':\n","        word = word[0:-1]\n","  except:\n","    dfdsd = 3\n","  if(word in model):\n","      return np.array(model[word])\n","  else:\n","    return np.zeros((300))\n","\n","def audioDataHelper(X):\n","    for i in range(X.shape[0]):\n","        if(X[i,1] == 0):\n","            X[i,0] = 0\n","            for j in range(7):\n","                X[i,j+1] = 0\n","    X = np.array(X)\n","    return X\n","    \n","def getAudioData(patientID, location, textD):\n","  fileName = \"/content/drive/My Drive/MCA Dataset/\"+ location + \"/\" + str(int(patientID)) + \"_COVAREP.csv\"\n","  data = pd.read_csv(fileName,header = None)\n","  data = data.iloc[:,:].values\n","  data = audioDataHelper(data)\n","  # print(\"Audio Raw Data:\" + str(data.shape))\n","  sentenceDatas = []\n","  for sentence in textD:\n","    sentenceStartime = sentence[0]\n","    sentenceEndTime = sentence[1]\n","    startIndex = math.floor(sentenceStartime/0.01)\n","    endIndex = math.ceil(sentenceEndTime/0.01)\n","    sentenceData = data[startIndex: endIndex]\n","    sentenceData = np.average(sentenceData, axis = 0)\n","    sentenceData = np.array(sentenceData.reshape(1, -1))\n","    sentenceDatas.append(sentenceData)\n","  \n","  sentenceDatas = np.array(sentenceDatas)\n","  sentenceDatas = np.reshape(sentenceDatas, (textD.shape[0],-1))\n","  # print(\"Audio Final Data:\" + str(sentenceDatas.shape))\n","\n","  return sentenceDatas\n","\n","# Xtrain = []\n","Ytrain = []\n","# Xtest = []\n","Ytest = []\n","\n","\n","audio_train = []\n","text_train = []\n","\n","audio_test = []\n","text_test = []\n","\n","\n","lengths = []\n","for datapoint in dataset:\n","  # print(datapoint[0])\n","  if(checkDataPointExistence(datapoint[0], devData)):\n","\n","    # Data Point in Dev Set\n","    text,audio = getData(datapoint[0], dev_location)\n","    text = text[:,2:]\n","    audio_train.append(audio)\n","    text_train.append(text)\n","    Ytrain.append(datapoint[2])\n","    # print(data)\n","  if(checkDataPointExistence(datapoint[0], testData)):\n","    # Data Point in Test Set\n","    text,audio = getData(datapoint[0], test_location)\n","    text = text[:,2:]\n","    audio_test.append(audio)\n","    text_test.append(text)\n","    Ytest.append(datapoint[2])\n","  elif(checkDataPointExistence(datapoint[0], trainData)):\n","    # Data Point in Train Set\n","    text,audio = getData(datapoint[0], train_location)\n","    text = text[:,2:]\n","    audio_train.append(audio)\n","    text_train.append(text)\n","    Ytrain.append(datapoint[2])\n","  # lengths.append(data.shape[0])\n","model = []\n","gc.collect()\n","\n","def refactor(arr, size):\n","  temp = arr[0:min(len(arr),size), :]\n","  if (len(temp) < size):\n","    temp = np.concatenate((temp, np.zeros(((size - len(temp)), arr.shape[1]))), axis = 0 )\n","  return temp\n","\n","numberOfSentences = 1700\n","\n","for i in range(len(audio_train)):\n","  # Xtrain[i] = refactor(Xtrain[i], numberOfSentences)\n","  audio_train[i] = refactor(audio_train[i], numberOfSentences)\n","  text_train[i] = refactor(text_train[i], numberOfSentences)\n","  # print(Xtrain[i].shape)\n","\n","for i in range(len(audio_test)):\n","  audio_test[i] = refactor(audio_train[i], numberOfSentences)\n","  text_test[i] = refactor(text_train[i], numberOfSentences)\n","  # print(Xtest[i].shape)\n","\n","audio_test = np.array(audio_test)\n","text_test = np.array(text_test)\n","# text_test = text_test[:,:,2:]\n","\n","audio_train = np.array(audio_train)\n","text_train = np.array(text_train)\n","# dataset = []\n","gc.collect()\n","\n","print(audio_test.shape,text_test.shape)\n","print(audio_train.shape,text_train.shape)\n","\n","dataset = []\n","devData = []\n","trainData = []\n","testdata = []\n","gc.collect()\n","\n","Ytrain = np.array(Ytrain)\n","Ytest = np.array(Ytest)\n","\n","gc.collect()\n","\n","import sklearn\n","from sklearn import preprocessing\n","\n","def upsample(X_train,Y_train):\n","  X_train_0 = X_train[Y_train<10]\n","  X_train_1 = X_train[Y_train>=10]\n","\n","  Y_train_1 = Y_train[Y_train>=10]\n","  # print(Y_train_1.shape)\n","  # print(X_train_1.shape)\n","  size = X_train_0.shape[0] - X_train_1.shape[0]\n","  X = []\n","  Y = []\n","  X_train = list(X_train)\n","  Y_train = list(Y_train)\n","  while(size>0):\n","    size -= 1\n","    index = np.random.randint(0,X_train_1.shape[0]-1)\n","    leave_index = np.random.randint(0,len(X_train)-1)\n","    X_add = X_train_1[index]\n","    X_leave = X_train[leave_index]\n","\n","    Y_add = Y_train_1[index]\n","    Y_leave = Y_train[leave_index]\n","\n","    X_train[leave_index] = X_add\n","    X_train.append(X_leave)\n","\n","    Y_train[leave_index] = Y_add\n","    Y_train.append(Y_leave)\n","\n","\n","  X_train = np.array(X_train)\n","  Y_train = np.array(Y_train)\n","  return X_train,Y_train\n","\n","\n","audio_train = np.nan_to_num(audio_train)\n","text_train = np.nan_to_num(text_train)\n","\n","\n","audio_train, _ = upsample(audio_train,Ytrain)\n","text_train, Ytrain = upsample(text_train,Ytrain)\n","\n","gc.collect()\n","\n","for i in range(audio_train.shape[0]):\n","  audio_train[i] = sklearn.preprocessing.normalize(audio_train[i])\n","  text_train[i] = sklearn.preprocessing.normalize(text_train[i])\n","\n","audio_test = np.nan_to_num(audio_test)\n","text_test = np.nan_to_num(text_test)\n","\n","for i in range(audio_test.shape[0]):\n","  audio_test[i] = sklearn.preprocessing.normalize(audio_test[i])\n","  text_test[i] = sklearn.preprocessing.normalize(text_test[i])\n","\n","gc.collect()"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"stream","name":"stdout","text":["(25, 1700, 74) (25, 1700, 301)\n","(52, 1700, 74) (52, 1700, 301)\n"]},{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"QdvCKjFN7_Wh"},"source":["BILSTM MODEL WITH GATING (WORD LEVEL)"]},{"cell_type":"code","metadata":{"id":"NM2yjWWbvjXj","executionInfo":{"status":"ok","timestamp":1681398341345,"user_tz":-330,"elapsed":4554,"user":{"displayName":"Deepression SLP","userId":"18338550655322334499"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a35b0ce6-64e2-4686-ed0a-9f0e947d3627"},"source":["#Word Level\n","\n","#Text+Audio\n","import tensorflow as tf\n","\n","from tensorflow import keras\n","\n","from keras.layers import LSTM, Dense\n","from keras import layers\n","\n","import numpy as np\n","\n","class Highway(layers.Layer):\n","\n","  def __init__(self):\n","    super(Highway, self).__init__()\n","\n","  def build(self, input_shape):\n","    n_sentences = input_shape[1]\n","    n_features = input_shape[2]\n","    carry_bias = keras.initializers.Constant(value=-1.0)\n","    random_dist = keras.initializers.RandomNormal(mean=0.0, stddev=0.1)\n","\n","    carry_bias_2 = keras.initializers.Constant(value= 0.1)\n","\n","    self.W_T = self.add_weight(shape=(n_features, n_features),initializer = random_dist,trainable=True)\n","    self.b_T = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias, trainable=True)\n","    # self.W_T = tf.Variable(tf.random.truncated_normal([n_data_points,n_features, n_features], stddev=0.1),trainable=True)\n","    # self.b_T = tf.Variable(tf.constant(-1.0, shape=[n_data_points, n_sentences, n_features]),trainable=True)\n","   \n","    self.W = self.add_weight(shape=( n_features, n_features),initializer = random_dist, trainable=True)\n","    self.b = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias_2, trainable=True)\n","    # self.W = tf.Variable(tf.random.truncated_normal([n_data_points,n_features, n_features], stddev=0.1), trainable=True)\n","    # self.b = tf.Variable(tf.constant(0.1, shape=[n_data_points, n_sentences, n_features]), trainable=True)  \n","\n","\n","  def call(self, inputs):\n","    x = inputs\n","    T = tf.sigmoid(tf.matmul(x, self.W_T) + self.b_T, name=\"transform_gate\")\n","    H = tf.nn.relu(tf.matmul(x, self.W) + self.b, name=\"activation\")\n","    C = tf.subtract(1.0, T, name=\"carry_gate\")\n","    \n","    return tf.add(tf.multiply(H, T), tf.multiply(x, C), \"y\")\n","\n","\n","# Multiple Inputs\n","from keras.utils import plot_model\n","from keras.models import Model\n","from keras.layers import Input, Bidirectional\n","from keras.layers import Dense\n","from keras.layers import concatenate\n","\n","# first input model\n","input1 = Input(shape=(1700,74), name = 'Audio_input')\n","highway1 = Highway()(input1)\n","highway5 = Highway()(highway1)\n","highway6 = Highway()(highway5)\n","dense1 = Dense(74)(highway6)\n","\n","# second input model\n","# input2 = Input(shape=(1700,388), name = 'Video_input')\n","# highway2 = Highway()(input2)\n","# highway3 = Highway()(highway2)\n","# highway4 = Highway()(highway3)\n","# # dense8 = Dense(1000)(highway4)\n","# # dense9 = Dense(500)(dense8)\n","# dense7 = Dense(200)(highway4)\n","# dense2 = Dense(74)(dense7) \n","\n","input3 = Input(shape = (1700,301), name = 'Text_input')\n","# dense4 = Dense(1000)(input3)\n","# dense5 = Dense(500)(dense4)\n","dense6 = Dense(150)(input3)\n","dense3 = Dense(74)(dense6)\n","# merge input models\n","merge = concatenate([dense1,dense3], axis = 1)\n","# interpretation model\n","lstm = LSTM(128, dropout = 0.2, recurrent_dropout = 0.2)\n","bidire = Bidirectional(lstm)\n","output = Dense(1, activation='sigmoid')(bidire(merge))\n","model = Model(inputs=[input1, input3], outputs=output)\n","# summarize layers\n","print(model.summary())\n","# plot graph\n","plot_model(model)\n","optimizer = tf.keras.optimizers.Adam(learning_rate= 0.0001)\n","lf = tf.keras.losses.MeanSquaredLogarithmicError()\n","model.compile(optimizer=optimizer, loss=lf, metrics=[ keras.metrics.MeanSquaredError(), keras.metrics.AUC(),])\n","\n","# inp = np.array([audio_train,video_train,text_train], dtype = object)\n","\n","# filepath = '/content/drive/My Drive/MCA Dataset/checkFile.txt'\n","\n","# model.fit([audio_train,text_train],Ytrain, validation_split = 0.2, callbacks = tf.keras.callbacks.EarlyStopping(\n","#     monitor='val_loss', min_delta=0, patience=15, verbose=0, mode='min',\n","#     baseline=None, restore_best_weights=True),epochs=30, batch_size = 4)\n","\n","\n","\n","\n","# def Losses(Y_pred, Y_test):\n","#   sum = 0\n","#   for i in range(len(Y_pred)):\n","#     m = abs(Y_pred[i]-Y_test[i])**2\n","\n","\n","\n","\n","# from sklearn.metrics import classification_report\n","# pred = model.predict([audio_test, text_test])\n","# pred2 = model.predict([audio_train,video_train,text_train])\n","\n","# print(\"Accuracy = \", model.score([audio_test,video_test,text_test],Ytest))\n","\n","# print(classification_report(Ytest,Thresholding(pred,0.5)))\n","# print(\"TRAINING ACCCCCC        \" , classification_report(Ytrain,Thresholding(pred2,0.5)))\n","# print(classification_report(Ytest,Thresholding(pred,0.6)))\n","# print(classification_report(Ytest,Thresholding(pred,0.4)))\n","# print(classification_report(Ytest,Thresholding(pred,0.3)))\n","# print(classification_report(Ytest,Thresholding(pred,0.7)))\n","\n","\n"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," Audio_input (InputLayer)       [(None, 1700, 74)]   0           []                               \n","                                                                                                  \n"," highway (Highway)              (None, 1700, 74)     262552      ['Audio_input[0][0]']            \n","                                                                                                  \n"," highway_1 (Highway)            (None, 1700, 74)     262552      ['highway[0][0]']                \n","                                                                                                  \n"," Text_input (InputLayer)        [(None, 1700, 301)]  0           []                               \n","                                                                                                  \n"," highway_2 (Highway)            (None, 1700, 74)     262552      ['highway_1[0][0]']              \n","                                                                                                  \n"," dense_1 (Dense)                (None, 1700, 150)    45300       ['Text_input[0][0]']             \n","                                                                                                  \n"," dense (Dense)                  (None, 1700, 74)     5550        ['highway_2[0][0]']              \n","                                                                                                  \n"," dense_2 (Dense)                (None, 1700, 74)     11174       ['dense_1[0][0]']                \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 3400, 74)     0           ['dense[0][0]',                  \n","                                                                  'dense_2[0][0]']                \n","                                                                                                  \n"," bidirectional (Bidirectional)  (None, 256)          207872      ['concatenate[0][0]']            \n","                                                                                                  \n"," dense_3 (Dense)                (None, 1)            257         ['bidirectional[0][0]']          \n","                                                                                                  \n","==================================================================================================\n","Total params: 1,057,809\n","Trainable params: 1,057,809\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["model.fit([audio_train,text_train],Ytrain, validation_split = 0.2, callbacks = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss', min_delta=0, patience=15, verbose=0, mode='min',\n","    baseline=None, restore_best_weights=True),epochs=8, batch_size = 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WcImintLW4A2","executionInfo":{"status":"ok","timestamp":1681407470099,"user_tz":-330,"elapsed":63548,"user":{"displayName":"Deepression SLP","userId":"18338550655322334499"}},"outputId":"7c739a49-1732-438c-94f0-54e10fc141a8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/8\n","31/31 [==============================] - 981s 32s/step - loss: 2.1225 - mean_squared_error: 65.4468 - auc: 0.5404 - val_loss: 3.3459 - val_mean_squared_error: 142.7298 - val_auc: 0.5000\n","Epoch 2/8\n","31/31 [==============================] - 983s 32s/step - loss: 2.0326 - mean_squared_error: 64.5459 - auc: 0.5000 - val_loss: 3.3435 - val_mean_squared_error: 142.7001 - val_auc: 0.5000\n","Epoch 3/8\n","31/31 [==============================] - 970s 31s/step - loss: 2.0320 - mean_squared_error: 64.5388 - auc: 0.5000 - val_loss: 3.3432 - val_mean_squared_error: 142.6960 - val_auc: 0.5000\n","Epoch 4/8\n","31/31 [==============================] - 966s 31s/step - loss: 2.0318 - mean_squared_error: 64.5369 - auc: 0.5000 - val_loss: 3.3430 - val_mean_squared_error: 142.6936 - val_auc: 0.5000\n","Epoch 5/8\n","31/31 [==============================] - 978s 32s/step - loss: 2.0317 - mean_squared_error: 64.5357 - auc: 0.5000 - val_loss: 3.3429 - val_mean_squared_error: 142.6922 - val_auc: 0.5000\n","Epoch 6/8\n","31/31 [==============================] - 976s 31s/step - loss: 2.0316 - mean_squared_error: 64.5351 - auc: 0.5000 - val_loss: 3.3428 - val_mean_squared_error: 142.6911 - val_auc: 0.5000\n","Epoch 7/8\n","31/31 [==============================] - 970s 31s/step - loss: 2.0316 - mean_squared_error: 64.5345 - auc: 0.5000 - val_loss: 3.3428 - val_mean_squared_error: 142.6905 - val_auc: 0.5000\n","Epoch 8/8\n","31/31 [==============================] - 942s 30s/step - loss: 2.0315 - mean_squared_error: 64.5340 - auc: 0.5000 - val_loss: 3.3427 - val_mean_squared_error: 142.6900 - val_auc: 0.5000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f852ab85190>"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["print(\"Loss = \", model.evaluate([audio_test,text_test],Ytest))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_OK7fSVKNVZR","executionInfo":{"status":"ok","timestamp":1681408727824,"user_tz":-330,"elapsed":3265,"user":{"displayName":"Deepression SLP","userId":"18338550655322334499"}},"outputId":"30ca7ce8-d893-4fa0-f4ea-b98c7d2b6d1c"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 3s 3s/step - loss: 2.2364 - mean_squared_error: 102.9217 - auc: 0.5000\n","Loss =  [2.236429452896118, 102.92167663574219, 0.5]\n"]}]}]}